# ğŸ§  Proyecto MÃ³dulo 3 â€“ PreparaciÃ³n de Datos

Este repositorio contiene el desarrollo completo del proyecto de **PreparaciÃ³n de Datos**, realizado en el marco del MÃ³dulo 3 del curso de Ciencia de Datos. El proyecto aborda el proceso de generaciÃ³n, recolecciÃ³n, limpieza, transformaciÃ³n e integraciÃ³n de datos provenientes de mÃºltiples fuentes, dejando un dataset final listo para anÃ¡lisis.

---

## ğŸ“ Estructura del repositorio

â”œâ”€â”€ Proyecto mÃ³dulo 3_F. Rojas.ipynb # Notebook principal con el flujo completo del proyecto
â”œâ”€â”€ datos_clientes.npy # Datos base de clientes generados con NumPy
â”œâ”€â”€ datos_transacciones.npy # Datos de transacciones simuladas
â”œâ”€â”€ datos_sucios_clientes.csv # Dataset de clientes sin limpiar
â”œâ”€â”€ datos_sucios_transacciones.xlsx # Dataset de transacciones sin limpiar
â”œâ”€â”€ datos_uf_2025.csv # Valores de la UF 2025 extraÃ­dos desde la web
â”œâ”€â”€ datos_unificados.csv # Dataset consolidado de mÃºltiples fuentes
â”œâ”€â”€ datos_limpio.csv # Dataset tras limpieza inicial
â”œâ”€â”€ datos_optimizado.csv # Dataset con variables transformadas
â”œâ”€â”€ dataset_final_limpio.csv # Dataset final listo para anÃ¡lisis
â”œâ”€â”€ Reporte_2025.xlsx # Reporte con mÃ©tricas y resÃºmenes


---

## ğŸ§© DescripciÃ³n del proyecto

El objetivo del proyecto es implementar un flujo de trabajo eficiente para la preparaciÃ³n de datos, utilizando **NumPy y Pandas**, que permita integrar informaciÃ³n de distintas fuentes, asegurar la calidad de los datos y estructurarlos adecuadamente para su posterior anÃ¡lisis.

El proceso incluye generaciÃ³n de datos sintÃ©ticos, extracciÃ³n de informaciÃ³n desde fuentes externas, limpieza, transformaciÃ³n y consolidaciÃ³n en un Ãºnico DataFrame.

---

## ğŸ›  TÃ©cnicas aplicadas

- GeneraciÃ³n de datos sintÃ©ticos mediante **NumPy**.
- ExtracciÃ³n de datos externos desde pÃ¡ginas web (valores de UF 2025).
- IntegraciÃ³n de mÃºltiples fuentes (CSV, Excel y HTML).
- Limpieza de datos:
  - EliminaciÃ³n de duplicados.
  - ImputaciÃ³n de valores nulos.
  - Tratamiento de outliers mediante el mÃ©todo IQR.
- NormalizaciÃ³n y ajuste de tipos de datos.
- CreaciÃ³n de variables derivadas para enriquecer el dataset.
- Agrupamiento y generaciÃ³n de mÃ©tricas resumen con `groupby()`.

---

## ğŸš€ Principales decisiones tÃ©cnicas

- Se definiÃ³ el **aÃ±o 2025 como referencia temporal** para la generaciÃ³n de los datos, con el objetivo de mantener coherencia con los valores de la UF extraÃ­dos desde fuentes externas.
- Las tablas obtenidas desde la web requirieron un proceso especÃ­fico de limpieza, incluyendo selecciÃ³n de columnas relevantes, normalizaciÃ³n de nombres y conversiÃ³n de tipos de datos.
- El flujo de trabajo se orientÃ³ a priorizar la **calidad, consistencia y reutilizaciÃ³n** del dataset final.

---

## ğŸ“¦ Requisitos

Para ejecutar el notebook se requiere:

- Python 3.x
- NumPy
- Pandas
- openpyxl (para manejo de archivos Excel)

InstalaciÃ³n de dependencias:

```bash
pip install numpy pandas openpyxl
